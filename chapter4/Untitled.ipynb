{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4939af3-8f8f-4899-8846-77336cb67482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11b2fde1-63af-41bd-bfb9-1ac51b78c4f0",
   "metadata": {},
   "source": [
    "### Efficiently Using Pretrained Models: A Guide to Avoiding Redundant Downloads\n",
    "\n",
    "In machine learning, utilizing pretrained models can accelerate development and enhance performance. However, constantly downloading these models can be time-consuming and inefficient. This post delves into a practical solution using Facebook Research's Dinov2 project as an example, focusing on how to load pretrained models locally to avoid redundant downloads.\n",
    "\n",
    "#### Why Avoid Redundant Downloads?\n",
    "\n",
    "Repeatedly downloading large model files wastes bandwidth and time. By storing models locally, you can streamline your workflow and ensure you always have the necessary resources at hand.\n",
    "\n",
    "#### Steps to Load Pretrained Models Locally\n",
    "\n",
    "1. **Download the Model Once**: Obtain the pretrained model weights and save them locally. This can be done by downloading and unzipping the model files.\n",
    "\n",
    "2. **Initialize the Model**: Use the `vision_transformer` module from `dinov2.models` to initialize the model architecture.\n",
    "\n",
    "   ```python\n",
    "   from dinov2.models import vision_transformer as vit\n",
    "   model = vit.__dict__['dinov2_vitb14'](pretrained=False)\n",
    "   ```\n",
    "\n",
    "3. **Load Pretrained Weights**: Use `torch.load` to load the weights into the model.\n",
    "\n",
    "   ```python\n",
    "   import torch\n",
    "   checkpoint = torch.load('path_to_model_weights.pth')\n",
    "   model.load_state_dict(checkpoint['model'])\n",
    "   ```\n",
    "\n",
    "4. **Utilize PyTorch Hub Cache**: Ensure model weights are stored in the PyTorch Hub cache directory to prevent repeated downloads.\n",
    "\n",
    "#### Practical Example\n",
    "\n",
    "To make this process concrete, let's walk through a practical example. First, download and unzip the pretrained model:\n",
    "\n",
    "```bash\n",
    "wget https://path_to_model_weights.zip -O model_weights.zip\n",
    "unzip model_weights.zip -d /path_to_model_weights\n",
    "```\n",
    "\n",
    "Next, initialize and load the model in your script:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from dinov2.models import vision_transformer as vit\n",
    "\n",
    "model = vit.__dict__['dinov2_vitb14'](pretrained=False)\n",
    "checkpoint = torch.load('/path_to_model_weights/model_weights.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "```\n",
    "\n",
    "By following these steps, you can efficiently use pretrained models without the hassle of redundant downloads.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Leveraging pretrained models locally not only saves time but also enhances productivity. Implementing the steps outlined in this post ensures that your machine learning projects run smoothly and efficiently. For more details, check out the [Dinov2 GitHub issue #91](https://github.com/facebookresearch/dinov2/issues/91).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "363c43fc-eba1-451d-bc8f-c13464eafdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "REPO_PATH = \"/home/shravan/documents/deeplearning/github/my_books/Machine_Learning_with_Python_Book/chapter4/dinov2/dinov2/\" # Specify a local path to the repository (or use installed package instead)\n",
    "sys.path.append(\"/home/shravan/documents/deeplearning/github/my_books/Machine_Learning_with_Python_Book/chapter4/dinov2/dinov2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea09d444-70e2-4bc2-a60a-9e3153b0c40a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dinov2.models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdinov2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m vision_transformer \u001b[38;5;28;01mas\u001b[39;00m vit\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m vit\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdinov2_vitb14\u001b[39m\u001b[38;5;124m'\u001b[39m](pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dinov2.models'"
     ]
    }
   ],
   "source": [
    "from dinov2.models import vision_transformer as vit\n",
    "model = vit.__dict__['dinov2_vitb14'](pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59510916-da39-47c6-b8ae-96db158a126d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf-dev",
   "language": "python",
   "name": "hf_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
